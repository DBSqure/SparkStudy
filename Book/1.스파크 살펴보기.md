---
tags:
  - "#Spark"
created: 2024-05-04
---


## 1. Apache Spark 란?

- 클러스터 환경에서 데이터를 병렬로 처리하는 라이브러리 집합

### A. Spark 철학

- 통합
	- "빅데이터 애플리케이션 개발에 필요한 통합 플랫포 제공"
- 컴퓨팅 엔진
	- 통합이라는 관점을 중시하여 기능의 범위를 컴퓨팅 엔진으로 제한
	- 데이터 연산하는 역할만 수행하며 영구 저장소 역할을 수행하지 않음
	- 데이터 저장 위치에 상관없이 처리에 집중
- 라이브러리

### B. Spark 등장 배경

- 2005년경 부터 하드웨어 성능 향상에 한계
- 단일 프로세스 성능을 향상시키는 방법 대신 모든 코어가 같은 속도로 동작하는 CPU 코어를 추가하는 방향으로 전환 => 병렬 처리
- 기존의 데이터 처리하는 방식이 아닌 새로운 프로그래밍 모델이 필요 => Spark 탄생


### C. Spark 역사

- 2009년 스파크 연구 프로젝트에서 시작
- 하둡 맵리듀스를 사용하여 데이터를 병렬 처리하는 과정에서 문제점을 확인
	- 맵리듀스를 활용하기 사용하는 대규모 어플리케이션의 난이도와 효율성 문제
	- 맵리듀스 처리를 위해 단계적으로 잡을 개발하고 클러스터에서 각각 실행하는 데 어려움
	- 매번 실행 때마다 데이터를 처음부터 읽어야 하는 문제가 있음
- 위의 문제 해결
	- 연산 단계 사이에서 메모리에 저장된 데이터를 효율적으로 공유할 수 있는 새로운 엔진 기반 API 구현
	- 초기 버전 : 함수형 연산(맵리듀스 같은 병렬 연산을 수행하는 API)
	- ver 1.0 : Spark SQL(구조화된 데이터를 기반으로 동작하는 API)
	- 현재 : DataFrame, 머신러닝 파이프라인, 구조적 스트리밍 등 API 제공


## 2. Spark Architecture

- 스파크는 클러스터의 데이터 처리 작업을 관리하고 조율
- 사용자 => 클러스터 매니저에 제출
- 클러스터 매니저는 애플리케이션 실행에 필요한 자원을 할당하며, 우리는 할당받은 자원으로 작업을 처리

### A. Spark Application

- 드라이버(driver) 프로세스, 익스큐터(executor) 프로세스로 구성
- 드라이버 프로세스 `SparkSession`
	- 클러스터 노드 중 하나에 실행하며 `main()` 함수를 실행
	- 스파크 애플리케이션 유지 관리, 사용자 입력에 대한 응답, 배포, 스케줄링 역할 등
	- 애플리케이션의 수명 주기 동안 관련 정보 모두 유지
- 익스큐터 프로세스
	- 드라이버 프로세스가 할당한 작업을 수행
- `SparkSession`  객체를 진입점으로 사용하여 사용자가 다른 언어로 작성하더라도 JVM에서 실행할 수 있는 코드로 변환
- Spark API
	- 2가지 API를 제공
	- 저수준의 비구조적 API
	- 고수준의 구조적 API






