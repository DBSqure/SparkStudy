---
tags:
  - "#Spark"
created: 2024-05-05
---


## 1. 데이터 타입 다루기

### A. 데이터 타입 변환

- `lit` 함수를 사용해 데이터 타입 변환
	- 다른 언어의 데이터 타입을 스파크 데이터 타입에 맞게 변환

```python
from pyspark.sql.functions import lit

df.select(lit(5), lit("five"), lit(5.0))
```
```
Out[4]: DataFrame[5: int, five: string, 5.0: double]
```


### B. boolean 데이터 타입

- true, false, and, or을 활용해 필터링
```python
from pyspark.sql.functions import col
from pyspark.sql.functions import instr

priceFilter = col("UnitPrice") > 600
descripFilter = instr(df.Description, "POSTAGE") >= 1
df.where(df.StockCode.isin("DOT")).where(priceFilter | descripFilter).show()
```
```
+---------+---------+--------------+--------+-------------------+---------+----------+--------------+
|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|
+---------+---------+--------------+--------+-------------------+---------+----------+--------------+
|   536544|      DOT|DOTCOM POSTAGE|       1|2010-12-01 14:32:00|   569.77|      null|United Kingdom|
|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      null|United Kingdom|
+---------+---------+--------------+--------+-------------------+---------+----------+--------------+
```

- boolean 컬럼을 활용해 DF 필터링
```python
from pyspark.sql.functions import col
from pyspark.sql.functions import instr

DOTCodeFilter = col("StockCode") == "DOT"
priceFilter = col("UnitPrice") > 600
descripFilter = instr(col("Description"), "POSTAGE") >= 1
df.withColumn("isExpensive", DOTCodeFilter & (priceFilter | descripFilter))\
  .where("isExpensive")\
  .select("unitPrice", "isExpensive").show(5)
```

- null 값 데이터 확인을 위해 null 값에 안전한지 동치 테스트 
```python
df.where(col("Description").eqNullSafe("hello")).show()
```


### C. 수치형 데이터 타입

- 일반적으로 연산 방식을 정의하는 형태로 사용
```python
from pyspark.sql.functions import expr, pow

new_num = pow(col("Quantity") * col("UnitPrice"), 2) + 5
df.select(expr("CustomerID"), new_num.alias("realQuantity")).show(2)
```
```
+----------+------------------+
|CustomerID|      realQuantity|
+----------+------------------+
|   17850.0|239.08999999999997|
|   17850.0|          418.7156|
+----------+------------------+
```

#### 반올림, 내림
- 반올림 `round`, 내림 `bround`
```python
from pyspark.sql.functions import lit, round, bround

df.select(round(lit("2.5")), bround(lit("2.5"))).show(2)
```

#### 고유 번호 붙이기
```python
from pyspark.sql.functions import monotonically_increasing_id

df.select(monotonically_increasing_id()).show(2)
```
```
+-----------------------------+
|monotonically_increasing_id()|
+-----------------------------+
|                            0|
|                            1|
+-----------------------------+
```
